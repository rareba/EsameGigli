setwd("C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Metodi Supervisionati")
credit<-read.table("credit_logit.csv", sep=",", header=T)
View(credit)
names(credit)
dim(credit)
mlogit=glm(y~acc1+acc2+duration+amount+moral+intuse, data=credit,family=binomial)
summary(mlogit)
coef(mlogit)
summary(mlogit)
coef(mlogit)
mlogit$coefficients[2]
summary(mlogit)$coef
attach(credit)
S=predict(mlogit,type="response")
summary(s)
summary(S)
attach(credit)
roc.curve=function(s,print=FALSE){
Ps=(S>s)*1
FP=sum((Ps==1)*(y==0))/sum(y==0)
TP=sum((Ps==1)*(y==1))/sum(y==1)
if(print==TRUE){
print(table(Observed=y,Predicted=Ps))
}
vect=c(FP,TP)
names(vect)=c("FPR","TPR")
return(vect)
}
threshold = 0.5
y=credit$y
roc.curve(threshold,print=TRUE)
threshold = 0.5
y=credit$y
roc.curve(threshold,print=TRUE)
threshold = 0.3
roc.curve(threshold,print=TRUE)
ROC.curve=Vectorize(roc.curve)
I=(((S>threshold)&(y==0))|((S<=threshold)&(y==1)))
plot(S,y,col=c("red","blue")[I+1],pch=19,cex=.7,,xlab="",ylab="")
abline(v=threshold,col="gray")
M.ROC=ROC.curve(seq(0,1,by=.01))
plot(M.ROC[1,],M.ROC[2,],col="grey",lwd=2,type="l", main="ROC curve",  xlab="False Positive Rate" , ylab="True positive rate",)
library(pROC)
install.packages("pROC")
plot(roc(y,S),legacy.axes = TRUE)
library(pROC)
plot(roc(y,S),legacy.axes = TRUE)
plot.roc(y, S, main="ROC Curve", percent=TRUE,legacy.axes = TRUE,
ci=TRUE, of="thresholds", # compute AUC (of threshold)
thresholds="best", # select the (best) threshold
print.thres="best") # also highlight this threshold on the plot
rm(list=ls(all=TRUE))
library(rpart)
source("C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/MBD2016-Functions-20160503.R")
file.data <- "C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/energydata_complete.csv"
data <- read.table(file = file.data, header = TRUE, sep = ",",
na.strings = "NA", colClasses = NA, check.names = FALSE, comment.char = "")
colnames(data)[colnames(data) == "date"] <- "time"
time <- strptime(x = data$time, format = "%Y-%m-%d %H:%M:%S", tz = "")
month <- format(x = time, format = "%m")
tmp <- NROW( levels(cut(x = time, breaks = "week")) )
week <- cut(x = time, breaks = "week", labels = 1 : tmp )
weekday <- weekdays(x = time, abbreviate = TRUE)
hour <- format(x = time, format = "%H")
lightsF <- data$lights
lightsF[lightsF >= 40] <- 40
lightsF <- factor(lightsF)
data <- data.frame(data, month = month, week = week, weekday = weekday, hour = hour,
Appliances.log = log(data$Appliances), lightsF = lightsF,
check.names = FALSE)
nobs <- NROW(data)
in1 <- round( nobs * 0.70 )
train <- data[ 1 : in1, , drop = FALSE]
test  <- data[ (in1 + 1) : nobs, , drop = FALSE]
cat( "dim(data)  = ", dim(data), "\n" )
cat( "dim(train) = ", dim(train), "\n" )
cat( "dim(test)  = ", dim(test), "\n" )
formula <- Appliances.log ~ weekday + hour + lightsF +
T2 + T3 + T8 + T9 +
RH_1 + RH_2 + RH_3 + RH_4 + RH_5 + RH_6 + RH_8 + RH_9 +
T_out + RH_out + Windspeed
fit <- lm(formula = formula, data = train)
fit.lm <- fit
formula <- Appliances.log ~ weekday + hour + lightsF +
T1 + T2 + T3 + T4 + T5 + T6 + T7 + T8 + T9 +
RH_1 + RH_2 + RH_3 + RH_4 + RH_5 + RH_6 + RH_7 + RH_8 + RH_9 +
T_out + RH_out + Windspeed + Visibility + Tdewpoint
control <- rpart.control(
minsplit = 20, ## Minimum number of observations in a node (group)
cp = 0.01,     ## Minimum cp decrease: any split not decreasing "rel error"
##  by a factor of cp is not attempted
## With "anova", the overall R-squared must increase by cp
##  at each step.
xval = 10)     ## Number of cross-validations to compute xerror
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE)  ## model = TRUE useful for kfold-cv
par(mfrow = c(1,1))
plot(x = fit, uniform = FALSE, branch = 1, compress = FALSE, margin = 0, minbranch = 0.3)
text(fit)        ## Adds text, values and labels
print(fit)
printcp(fit)
plotcp(fit, minline = FALSE)
model <- fit
yVar <- rownames(attr(terms(model), "factors"))[1]
y <- train[, yVar]
layout(matrix(1:2, nc = 1))
plot(model, uniform = FALSE, margin = 0.1, branch = 1, compress = TRUE)
text(model)
rnames <- rownames(model$frame)
lev    <- rnames[sort(unique(model$where))]
where  <- factor(rnames[model$where], levels = lev)
boxplot(y ~ where, varwidth = TRUE,
ylim = range(y) * c(0.8, 1.2),
pars = list(axes = FALSE), ylab = yVar)
abline(h = mean(y), lty = 3)
axis(2)
n <- tapply(y, where, length)
text(1:length(n), max(y) * 1.2, paste("n = ", n))
rm(list=ls(all=TRUE))
library(MASS)
library(glmnet)
library(mgcv)
source("C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/MBD2016-Functions-20160503.R")
.ftest <-
function(fit0, fit1)
.ftest <-
function(fit0, fit1)
{
## FUNCTION:
#### ANOVA
tab <- anova(fit0, fit1)
#### Statistic
D0 <- tab[1, 2]
D1 <- tab[2, 2]
rdf0 <- tab[1, 1]
rdf1 <- tab[2, 1]
fstat <- (D0 - D1) / (D1 / rdf1)
df1 <- rdf0 - rdf1
df2 <- rdf1
pvalue <- 1 - pf(q = fstat, df1 = df1, df2 = df2)
#### Answer
c(D0 = D0, D1 = D1, rdf0 = rdf0, rdf1 = rdf1,
fstat = fstat, df1 = df1, df2 = df2, pvalue = pvalue)
}
.ftest.all <-
function(fit)
.ftest.all <-
function(fit)
{
## FUNCTION:
#### terms
formula <- fit$formula
vars <- rownames(attr(x = terms(formula), which = "factors"))
vY <- vars[ 1]
vX <- vars[-1]
data <- fit$model
#### Find spline terms
x1  <- strsplit(x = vX, split = "[(]|,")
ind <- which( mapply(FUN = "[", x1, 1) == "s" & mapply(FUN = "NROW", x1) > 1 )
vXT <- mapply(FUN = "[", x1[ind], 2)
#### Initialize
ans <- vector(length = NROW(ind), mode = "list")
j <- 0
#### Trace
cat("Linearity tests:\n")
#### Cycle
for ( i in ind )
{
#### Prog
j <- j + 1
#### Trace
cat(vXT[j], ", ")
#### Compose formula
vX0 <- vX
vX0[i] <- vXT[j]
formula0 <- paste0( vY, " ~ ", paste0( vX0 , collapse = " + "))
formula0 <- as.formula(formula0)
#### Estimate
fit0 <- gam(formula = formula0, family = fit$family, data = fit$model, scale = 0)
#### Test
ans[[j]] <- .ftest(fit0 = fit0, fit1 = fit)
}
#### Answer
data.frame(Var = vXT, do.call(what = rbind, args = ans),
check.names = FALSE)
}
file.data <- "C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/energydata_complete.csv"
data <- read.table(file = file.data, header = TRUE, sep = ",",
na.strings = "NA", colClasses = NA, check.names = FALSE, comment.char = "")
colnames(data)[colnames(data) == "date"] <- "time"
time <- strptime(x = data$time, format = "%Y-%m-%d %H:%M:%S", tz = "")
month <- format(x = time, format = "%m")
tmp <- NROW( levels(cut(x = time, breaks = "week")) )
week <- cut(x = time, breaks = "week", labels = 1 : tmp )
weekday <- weekdays(x = time, abbreviate = TRUE)
hour <- format(x = time, format = "%H")
lightsF <- data$lights
lightsF[lightsF >= 40] <- 40
lightsF <- factor(lightsF)
data <- data.frame(data, month = month, week = week, weekday = weekday, hour = hour,
Appliances.log = log(data$Appliances), lightsF = lightsF,
check.names = FALSE)
nobs <- NROW(data)
in1 <- round( nobs * 0.30 )
train <- data[ 1 : in1, , drop = FALSE]
test  <- data[ (in1 + 1) : nobs, , drop = FALSE]
cat( "dim(data)  = ", dim(data), "\n" )
cat( "dim(train) = ", dim(train), "\n" )
cat( "dim(test)  = ", dim(test), "\n" )
yVar <- "Appliances.log"
xVar <- c( "T1", "RH_1", "T2", "RH_2", "T3", "RH_3", "T4", "RH_4", "T5", "RH_5",
"T6", "RH_6", "T7", "RH_7", "T8", "RH_8", "T9", "RH_9",
"T_out", "Press_mm_hg", "RH_out", "Windspeed", "Visibility", "Tdewpoint",
"weekday", "hour", "lightsF")
formula <- Appliances.log ~ weekday + hour + lightsF +
T2 + T3 + T8 + T9 +
RH_1 + RH_2 + RH_3 + RH_4 + RH_5 + RH_6 + RH_8 + RH_9 +
T_out + RH_out + Windspeed
fit <- lm(formula = formula, data = train)
fit.lm <- fit
fx <- FALSE    ## Try TRUE and FALSE; explain
k  <- 12       ## Try different choices; explain
formula <- Appliances.log ~ weekday + hour + lightsF +
s(T2,        bs = "cr", k = k, fx = fx) +
s(T3,        bs = "cr", k = k, fx = fx) +
s(T8,        bs = "cr", k = k, fx = fx) +
s(T9,        bs = "cr", k = k, fx = fx) +
s(RH_1,      bs = "cr", k = k, fx = fx) +
s(RH_2,      bs = "cr", k = k, fx = fx) +
s(RH_3,      bs = "cr", k = k, fx = fx) +
s(RH_4,      bs = "cr", k = k, fx = fx) +
s(RH_5,      bs = "cr", k = k, fx = fx) +
s(RH_6,      bs = "cr", k = k, fx = fx) +
s(RH_8,      bs = "cr", k = k, fx = fx) +
s(RH_9,      bs = "cr", k = k, fx = fx) +
s(T_out,     bs = "cr", k = k, fx = fx) +
s(RH_out,    bs = "cr", k = k, fx = fx) +
s(Windspeed, bs = "cr", k = k, fx = fx)
fit <- gam(formula = formula, family = gaussian(), data = train, method = "GCV.Cp",
scale = 0)
fit.gam <- fit
formula0 <- Appliances.log ~ weekday + hour + lightsF +
s(T2,        bs = "cr", k = k, fx = fx) +
s(T3,        bs = "cr", k = k, fx = fx) +
s(T8,        bs = "cr", k = k, fx = fx) +
s(T9,        bs = "cr", k = k, fx = fx) +
s(RH_1,      bs = "cr", k = k, fx = fx) +
s(RH_2,      bs = "cr", k = k, fx = fx) +
s(RH_3,      bs = "cr", k = k, fx = fx) +
s(RH_4,      bs = "cr", k = k, fx = fx) +
s(RH_5,      bs = "cr", k = k, fx = fx) +
s(RH_6,      bs = "cr", k = k, fx = fx) +
s(RH_8,      bs = "cr", k = k, fx = fx) + RH_9 +
s(T_out,     bs = "cr", k = k, fx = fx) +
s(RH_out,    bs = "cr", k = k, fx = fx) +
s(Windspeed, bs = "cr", k = k, fx = fx)
fit0 <- gam(formula = formula0, family = gaussian(), data = train,
method = "GCV.Cp", scale = 0)
test0 <- .ftest(fit0 = fit0, fit1 = fit)
test.all <- .ftest.all(fit = fit)
k <- 10
seed <- 100000
cv.lm  <- .kfoldcv(k = k, model = fit.lm,  seed = seed)
cv.gam <- .kfoldcv(k = k, model = fit.gam, seed = seed)
x1 <- c("lm", "gam")
x2 <- rbind(cv.lm, cv.gam)
kfold <- data.frame(Model = x1, x2, check.names = FALSE)
cat("k-fold CV", "\n")
print(kfold)
test.all
test
test.all
test0 <- .ftest(fit0 = fit0, fit1 = fit)
test.all <- .ftest.all(fit = fit)
test.all
rm(list=ls(all=TRUE))
library(rpart)
source("C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/MBD2016-Functions-20160503.R")
file.data <- "C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/energydata_complete.csv"
data <- read.table(file = file.data, header = TRUE, sep = ",",
na.strings = "NA", colClasses = NA, check.names = FALSE, comment.char = "")
formula <- Appliances.log ~ weekday + hour + lightsF +
T1 + T2 + T3 + T4 + T5 + T6 + T7 + T8 + T9 +
RH_1 + RH_2 + RH_3 + RH_4 + RH_5 + RH_6 + RH_7 + RH_8 + RH_9 +
T_out + RH_out + Windspeed + Visibility + Tdewpoint
control <- rpart.control(
minsplit = 20, ## Minimum number of observations in a node (group)
cp = 0.01,     ## Minimum cp decrease: any split not decreasing "rel error"
##  by a factor of cp is not attempted
## With "anova", the overall R-squared must increase by cp
##  at each step.
xval = 10)     ## Number of cross-validations to compute xerror
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE)  ## model = TRUE useful for kfold-cv
par(mfrow = c(1,1))
plot(x = fit, uniform = FALSE, branch = 1, compress = FALSE, margin = 0, minbranch = 0.3)
text(fit)        ## Adds text, values and labels
print(fit)
printcp(fit)
plotcp(fit, minline = FALSE)
model <- fit
rm(list=ls(all=TRUE))
library(rpart)
source("C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/MBD2016-Functions-20160503.R")
file.data <- "C:/Users/GiulioVannini/OneDrive - Il Gabbiano s.r.l/MasterMABIDA/Cipollini/energydata_complete.csv"
data <- read.table(file = file.data, header = TRUE, sep = ",",
na.strings = "NA", colClasses = NA, check.names = FALSE, comment.char = "")
colnames(data)[colnames(data) == "date"] <- "time"
time <- strptime(x = data$time, format = "%Y-%m-%d %H:%M:%S", tz = "")
month <- format(x = time, format = "%m")
tmp <- NROW( levels(cut(x = time, breaks = "week")) )
week <- cut(x = time, breaks = "week", labels = 1 : tmp )
weekday <- weekdays(x = time, abbreviate = TRUE)
hour <- format(x = time, format = "%H")
lightsF <- data$lights
lightsF[lightsF >= 40] <- 40
lightsF <- factor(lightsF)
data <- data.frame(data, month = month, week = week, weekday = weekday, hour = hour,
Appliances.log = log(data$Appliances), lightsF = lightsF,
check.names = FALSE)
nobs <- NROW(data)
in1 <- round( nobs * 0.70 )
train <- data[ 1 : in1, , drop = FALSE]
test  <- data[ (in1 + 1) : nobs, , drop = FALSE]
cat( "dim(data)  = ", dim(data), "\n" )
cat( "dim(train) = ", dim(train), "\n" )
cat( "dim(test)  = ", dim(test), "\n" )
formula <- Appliances.log ~ weekday + hour + lightsF +
T2 + T3 + T8 + T9 +
RH_1 + RH_2 + RH_3 + RH_4 + RH_5 + RH_6 + RH_8 + RH_9 +
T_out + RH_out + Windspeed
fit <- lm(formula = formula, data = train)
fit.lm <- fit
formula <- Appliances.log ~ weekday + hour + lightsF +
T1 + T2 + T3 + T4 + T5 + T6 + T7 + T8 + T9 +
RH_1 + RH_2 + RH_3 + RH_4 + RH_5 + RH_6 + RH_7 + RH_8 + RH_9 +
T_out + RH_out + Windspeed + Visibility + Tdewpoint
control <- rpart.control(
minsplit = 20, ## Minimum number of observations in a node (group)
cp = 0.01,     ## Minimum cp decrease: any split not decreasing "rel error"
##  by a factor of cp is not attempted
## With "anova", the overall R-squared must increase by cp
##  at each step.
xval = 10)     ## Number of cross-validations to compute xerror
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE)  ## model = TRUE useful for kfold-cv
par(mfrow = c(1,1))
plot(x = fit, uniform = FALSE, branch = 1, compress = FALSE, margin = 0, minbranch = 0.3)
text(fit)        ## Adds text, values and labels
print(fit)
printcp(fit)
plotcp(fit, minline = FALSE)
model <- fit
yVar <- rownames(attr(terms(model), "factors"))[1]
y <- train[, yVar]
layout(matrix(1:2, nc = 1))
plot(model, uniform = FALSE, margin = 0.1, branch = 1, compress = TRUE)
text(model)
rnames <- rownames(model$frame)
lev    <- rnames[sort(unique(model$where))]
where  <- factor(rnames[model$where], levels = lev)
boxplot(y ~ where, varwidth = TRUE,
ylim = range(y) * c(0.8, 1.2),
pars = list(axes = FALSE), ylab = yVar)
abline(h = mean(y), lty = 3)
axis(2)
n <- tapply(y, where, length)
text(1:length(n), max(y) * 1.2, paste("n = ", n))
fit.rpart1  <- fit
control <- rpart.control(
minsplit = 20, ## Minimum number of observations in a node
cp = 0.001,    ## Minimum cp decrease
xval = 10)     ## Number of cross-validations for xerror
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE, x = FALSE, y = TRUE)
plotcp(fit, minline = TRUE)
par(mfrow = c(1,2))
rsq.rpart(fit) ## Another useful plot (Relative vs Apparent)
ind <- which.min(fit$cptable[, "xerror"])
ind <- fit$cptable[, "xerror"] > min(fit$cptable[, "xerror"] + fit$cptable[, "xstd"])
ind <- which.min(fit$cptable[ind, "xerror"])
fit.rpart2  <- prune(tree = fit, cp = fit$cptable[ind, "CP"])   ## Prune
k <- 20
par(mfrow = c(1,1))
plot(x = fit, uniform = FALSE, branch = 1, compress = FALSE, margin = 0, minbranch = 0.3)
text(fit)        ## Adds text, values and labels
print(fit)
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE)  ## model = TRUE useful for kfold-cv
par(mfrow = c(1,1))
plot(x = fit, uniform = FALSE, branch = 1, compress = FALSE, margin = 0, minbranch = 0.3)
text(fit)        ## Adds text, values and labels
print(fit)
printcp(fit)
plotcp(fit, minline = FALSE)
model <- fit
yVar <- rownames(attr(terms(model), "factors"))[1]
y <- train[, yVar]
layout(matrix(1:2, nc = 1))
plot(model, uniform = FALSE, margin = 0.1, branch = 1, compress = TRUE)
text(model)
rnames <- rownames(model$frame)
lev    <- rnames[sort(unique(model$where))]
where  <- factor(rnames[model$where], levels = lev)
boxplot(y ~ where, varwidth = TRUE,
ylim = range(y) * c(0.8, 1.2),
pars = list(axes = FALSE), ylab = yVar)
abline(h = mean(y), lty = 3)
axis(2)
n <- tapply(y, where, length)
text(1:length(n), max(y) * 1.2, paste("n = ", n))
fit.rpart1  <- fit
control <- rpart.control(
minsplit = 20, ## Minimum number of observations in a node
cp = 0.001,    ## Minimum cp decrease
xval = 10)     ## Number of cross-validations for xerror
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE, x = FALSE, y = TRUE)
plotcp(fit, minline = TRUE)
par(mfrow = c(1,2))
rsq.rpart(fit) ## Another useful plot (Relative vs Apparent)
control <- rpart.control(
minsplit = 20, ## Minimum number of observations in a node
cp = 0.001,    ## Minimum cp decrease
xval = 10)     ## Number of cross-validations for xerror
fit <- rpart(formula = formula, data = train, method = "anova", control = control,
model = TRUE, x = FALSE, y = TRUE)
plotcp(fit, minline = TRUE)
par(mfrow = c(1,2))
rsq.rpart(fit) ## Another useful plot (Relative vs Apparent)
ind <- which.min(fit$cptable[, "xerror"])
ind <- fit$cptable[, "xerror"] > min(fit$cptable[, "xerror"] + fit$cptable[, "xstd"])
ind <- which.min(fit$cptable[ind, "xerror"])
fit.rpart2  <- prune(tree = fit, cp = fit$cptable[ind, "CP"])   ## Prune
k <- 20
seed <- 100000
cv.lm     <- .kfoldcv(k = k, model = fit.lm, seed = seed)
cv.rpart1 <- .kfoldcv(k = k, model = fit.rpart1, seed = seed)
cv.rpart2 <- .kfoldcv(k = k, model = fit.rpart2, seed = seed)
x1 <- c("lm", "rpart1", "rpart2")
x2 <- rbind(cv.lm, cv.rpart1, cv.rpart2)
fit.rpart2  <- prune(tree = fit, cp = fit$cptable[ind, "CP"])   ## Prune
k <- 20
seed <- 100000
cv.lm     <- .kfoldcv(k = k, model = fit.lm, seed = seed)
cv.rpart1 <- .kfoldcv(k = k, model = fit.rpart1, seed = seed)
cv.rpart2 <- .kfoldcv(k = k, model = fit.rpart2, seed = seed)
x1 <- c("lm", "rpart1", "rpart2")
x2 <- rbind(cv.lm, cv.rpart1, cv.rpart2)
kfold <- data.frame(Model = x1, x2, check.names = FALSE)
cat("k-fold CV", "\n")
print(kfold)
fit.rpart2  <- prune(tree = fit, cp = fit$cptable[ind, "CP"])   ## Prune
fit.rpart2
k <- 20
seed <- 100000
cv.lm     <- .kfoldcv(k = k, model = fit.lm, seed = seed)
cv.rpart1 <- .kfoldcv(k = k, model = fit.rpart1, seed = seed)
cv.rpart2 <- .kfoldcv(k = k, model = fit.rpart2, seed = seed)
x1 <- c("lm", "rpart1", "rpart2")
x2 <- rbind(cv.lm, cv.rpart1, cv.rpart2)
kfold <- data.frame(Model = x1, x2, check.names = FALSE)
cat("k-fold CV", "\n")
print(kfold)
str(df, list=101)
setwd("C:\Users\GiulioVannini\Documents\Visual Studio 2017\Projects\MABIDA2017\Grassini")
#install.packages("C50")
library(C50)
install.packages("C50", lib="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
#install.packages("C50")
library(C50)
setwd("C:/Users/GiulioVannini/Documents/Visual Studio 2017/Projects/MABIDA2017/Grassini")
crx <- read.table( file="expanded_AGARICUS_LEPIOTA.txt", header=TRUE, sep="," )
head(crx)
summary(crx)
set.seed(22)
crx <- crx[sample(nrow(crx)),] # Mischia i record, prima di estratte training e test set
crx$veil.type=NULL # ha un solo valore
X <- crx[,-1]
y <- crx[,1]
# Creazione training set e test set
trainX <- X[1:8000,]
trainy <- y[1:8000]
testX <- X[8001:8416,]
testy <- y[8001:8416]
# Realizzo il modello
model <- C5.0(trainX, trainy)
summary(model)
plot(model)
# Con variabile dipendente categorica/discreta
#install.packages("C50")
library(C50)
setwd("C:/Users/GiulioVannini/Documents/Visual Studio 2017/Projects/MABIDA2017/Grassini")
crx <- read.table( file="expanded_AGARICUS_LEPIOTA.txt", header=TRUE, sep="," )
head(crx)
summary(crx)
set.seed(22)
crx <- crx[sample(nrow(crx)),] # Mischia i record, prima di estratte training e test set
crx$veil.type=NULL # ha un solo valore
X <- crx[,-1]
y <- crx[,1]
# Creazione training set e test set
trainX <- X[1:8000,]
trainy <- y[1:8000]
testX <- X[8001:8416,]
testy <- y[8001:8416]
# Realizzo il modello
model <- C5.0(trainX, trainy)
summary(model)
plot(model)
# Aggiungo una matrice di costi per penalizzare l'erronea classificazione dei funghi
#levels(crx[,1])
cost_matrix<-matrix(c(0,10,1,0),2,2,byrow=TRUE)
cost_matrix
rownames(cost_matrix)<-levels(crx[,1])
colnames(cost_matrix)<-levels(crx[,1])
cost_matrix
model.1<-C5.0(trainX,trainy,costs=cost_matrix)
summary(model.1)
plot(model.1)
predizione<-predict(model.1,testX,type='class') ## classe assegnata dalla regola
summary(predizione)
table(testy,predizione)
probabilita<-predict(model,testX,type='prob')  ## probabilità
str(probabilita)
head(probabilita)
probabilita<-predict(model.1,testX,type='prob')  ## probabilità
str(probabilita)
head(probabilita)
probabilita<-predict(model,testX,type='prob')  ## probabilità
probabilita<-predict(model,testX,type='prob')  ## probabilità
str(probabilita)
head(probabilita)
install.packages("rpart.plot", lib="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
dove_commestibile<-which(probabilita[,1]>.5)
dove_nonCommestibile<-which(probabilita[,2]>.5)
####################################################################################
# Con variabile dipendente continua
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
#### File (adjust path)
file.data <- "C:/Users/GiulioVannini/Documents/Visual Studio 2017/Projects/MABIDA2017/Grassini/Income-training.csv"
remove <- c("", "Numero.di.FamiglieProvincia", "Numero.di.FamiglieRegione")
#### Read data
data <- read.table(file = file.data, header = TRUE, sep = ",",                     na.strings = "NA", colClasses = NA, check.names = FALSE, comment.char = "")
ind <- !( colnames(data) %in% remove )
data <- data[, ind, drop = FALSE]
# data$gini.index <- log(data$gini.index / (1 - data$gini.index))
## Levels on log scale
head(data)
## VAR on log scale
data <- data[sample(nrow(data)),] # Mischia i record, prima di estratte training e test set
#summary(data)
# Creazione training set e test set
datatr <- data[1:5500,]
datate <- data[5501:6071,]
# Le variabili che entrano nel nostro modello
formula <- gini.index ~ Regione + Popolazione.TotaleProvincia + Numero.medio.di.componenti.per.famigliaProvincia +             contribuenti
## Here a selection of the main control parameters
# Le variabili che entrano nel nostro modello
formula <- gini.index ~ Regione + Popolazione.TotaleProvincia + Numero.medio.di.componenti.per.famigliaProvincia +             contribuenti
## Here a selection of the main control parameters
control <- rpart.control(   minsplit = 20, ## Minimum number of observations in a node   cp = 0.0025,     ## Minimum cp decrease: any split not decreasing "rel error"                   ##  by a factor of cp is not attempted                  ## With "anova", the overall R-squared must increase by cp                   ##  at each step.    xval = 10)     ## Number of cross-validations for xerror
## Fit
fit <- rpart(formula = formula, data = datatr, method = "anova", control = control)
plot(x = fit, uniform = FALSE, branch = 0.1, compress = FALSE, margin = 0, minbranch = 0.3) 
text(fit)        ## Adds text, values and labels
plot(x = fit, uniform = FALSE, branch = 0.1, compress = FALSE, margin = 0, minbranch = 0.3) 
text(fit)        ## Adds text, values and labels
print(fit)
printcp(fit)
plotcp(fit, minline = FALSE)
## min(xerror)
ind <- which.min(fit$cptable[, "xerror"])
# Potatura
fit.prune <- prune(tree = fit, cp = fit$cptable[ind, "CP"]) 
print(fit.prune)
# Valutiamo il modello sul data test
dat<-datate[,c("Regione","Popolazione.TotaleProvincia","Numero.medio.di.componenti.per.famigliaProvincia",             "contribuenti")]
predizione<-predict(fit.prune,dat)
SE<-sqrt((predizione-datate[,"gini.index"])^2)
mean(SE)
summary(SE)
plot(SE)
summary(predizione)
predizione[1:20]
datate[,"gini.index"][1:20]
plot(fit.prune)
text(fit.prune)
library(readxl)    # free data from excel hades
library(dplyr)     # sane data manipulation
library(tidyr)     # sane data munging
library(viridis)   # sane colors
install.packages('dplyr')
library(readxl)    # free data from excel hades
library(dplyr)     # sane data manipulation
library(tidyr)     # sane data munging
library(viridis)   # sane colors
library(ggplot2)   # needs no introduction
library(ggfortify) # super-helpful for plotting non-"standard" stats objects
install.packages('ggfortify')
library(ggfortify) # super-helpful for plotting non-"standard" stats objects
my_seed = 0
setwd("~/Visual Studio 2017/Projects/MABIDA2017/Gigli/Management science/")
#The dataset contains both information on marketing newsletters/e-mail campaigns (e-mail offers sent) and 
#transaction level data from customers (which offer customers responded to and what they bought).
#get data
url <- "http://blog.yhathq.com/static/misc/data/WineKMC.xlsx"
d.file <- basename(url)
if (!file.exists(d.file)) download.file(url, d.file)
#Read Campaign Data
offers <- read_excel(d.file, sheet = 1)
install.packages("readOffice", lib="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
unloadNamespace("readxl")
library("readxl", lib.loc="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
library(readxl)    # free data from excel hades
library(dplyr)     # sane data manipulation
library(tidyr)     # sane data munging
library(viridis)   # sane colors
library(ggplot2)   # needs no introduction
library(ggfortify) # super-helpful for plotting non-"standard" stats objects
my_seed = 0
set.seed(my_seed)
setwd("~/Visual Studio 2017/Projects/MABIDA2017/Gigli/Management science/")
#The dataset contains both information on marketing newsletters/e-mail campaigns (e-mail offers sent) and 
#transaction level data from customers (which offer customers responded to and what they bought).
#get data
url <- "http://blog.yhathq.com/static/misc/data/WineKMC.xlsx"
d.file <- basename(url)
if (!file.exists(d.file)) download.file(url, d.file)
#Read Campaign Data
offers <- read_excel(d.file, sheet = 1)
library("readOffice", lib.loc="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
library(readOffice)    # free data from excel hades
offers <- readOffice(d.file, sheet = 1)
readxl
unloadNamespace("readOffice")
library(readxl)    # free data from excel hades
library(dplyr)     # sane data manipulation
library(tidyr)     # sane data munging
library(viridis)   # sane colors
library(ggplot2)   # needs no introduction
library(ggfortify) # super-helpful for plotting non-"standard" stats objects
my_seed = 0
set.seed(my_seed)
install.packages("ggfortify", lib="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
library("ggfortify", lib.loc="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
#get data
url <- "http://blog.yhathq.com/static/misc/data/WineKMC.xlsx"
d.file <- basename(url)
if (!file.exists(d.file)) download.file(url, d.file)
#Read Campaign Data
offers <- read_excel(d.file, sheet = 1)
offers <- read_excel("~/Visual Studio 2017/Projects/MABIDA2017/Gigli/Management science/WineKMC.xlsx", sheet = 1)
