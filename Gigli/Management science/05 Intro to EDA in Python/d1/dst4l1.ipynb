{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis and Statistics using Pandas and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###0. Preliminary plotting stuff to get things going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###0. Preliminaries about Python\n",
    "\n",
    "In working with python I always remember: a python is a duck.\n",
    "\n",
    "What I mean is, python has a certain way of doing things. For example lets call one of these ways listiness. Listiness works on lists, dictionaries, files, and a general notion of something called an iterator.\n",
    "\n",
    "But first, lets introduce the notion of a comprehension. Its a way of constructing a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alist=[1,2,3,4,5]\n",
    "asquaredlist=[i*i for i in alist]\n",
    "asquaredlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has some nifty functions like `enumerate` and `zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enumerate(asquaredlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats a strange type. But its really a duck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[k for k in enumerate(asquaredlist)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next one is very usefil in combining lists together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(alist, asquaredlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open files behave like lists too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linelengths=[len(line) for line in open(\"olive.csv\")]\n",
    "print linelengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so do dictionaries. But know what you are accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adict={'one':1, 'two': 2, 'three': 3}\n",
    "print [i for i in adict], [(k,v) for k,v in adict.items()], adict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xrange` is another duck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for i in xrange(10):\n",
    "    mylist.append(i)\n",
    "mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From python 2.7 onwards you can construct dictionaries using dictionary comprehensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{k:v for (k,v) in zip(alist, asquaredlist)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN NOW (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dictionary with keys the integers upto and including 10, and values the cubes of these dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. The Olive Oils dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the following text is taken from the rggobi book (http://www.ggobi.org/book/). It is an excellent book on visualization and EDA for classification, and is available freely as a pdf from Hollis for those with a Harvard Id. Even though the book uses ggobi, a lot of the same analysis can be done in Mondrian or directly in Matplotlib/Pandas (albeit not interactively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "\"The Olive Oils data has eight explanatory variables (levels of fatty acids in the oils) and nine classes (areas of Italy). The goal of the analysis is to develop rules that reliably distinguish oils from the nine different areas. It is a problem of practical interest, because oil from some areas is more highly valued and unscrupulous suppliers sometimes make false claims about the origin of their oil. The content of the oils is a subject of study in its own right: Olive oil has high nutritional value, and some of its constituent fatty acids are considered to be more beneficial than others.\"\n",
    "\n",
    "In addition, fatty acid contents vary with climate: this information is important in deciding which varieties to grow where.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Source: Forina, M., Armanino, C., Lanteri, S. & Tiscornia, E. (1983), Classification of Olive Oils from their Fatty Acid Composition, in Martens, H. and\n",
    "Russwurm Jr., H., eds, Food Research and Data Analysis, Applied Science\n",
    "Publishers, London, pp. 189â€“214. It was brought to our attention by Glover\n",
    "& Hopke (1992).\n",
    "\n",
    "Number of rows: 572\n",
    "\n",
    "Number of variables: 10\n",
    "\n",
    "Description: This data consists of the percentage composition of fatty acids\n",
    "found in the lipid fraction of Italian olive oils. The data arises from a study\n",
    "to determine the authenticity of an olive oil.\"\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Italy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In working with pandas and matplotlib I dont always remember the syntax. A programmer is a good tool for converting Stack Overflow snippets into code. I almost always put what I am trying to do into google and go from there. \n",
    "\n",
    "That said, I found the following links very useful in understanding the Pandas mode, how things work.\n",
    "\n",
    "* http://blog.yhathq.com/posts/R-and-pandas-and-what-ive-learned-about-each.html\n",
    "* http://www.bearrelroll.com/2013/05/python-pandas-tutorial/\n",
    "* http://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the olive oil dataset into a pandas dataframe and have a look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"olive.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename that ugly first column. \n",
    "\n",
    "*Hint*: A Google search for 'python pandas dataframe rename' points you at this <a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.rename.html\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.columns\n",
    "df.rename(columns={df.columns[0]:'areastring'}, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore. Which unique regions and areas are contained in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'regions\\t', df.region.unique()\n",
    "print 'areas\\t', df.area.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a *crosstab*ulation or contingency table of the factors.\n",
    "\n",
    "*Hint*: A Google search for 'python pandas cross tabulation' points you at this <a href=\"http://pandas.pydata.org/pandas-docs/stable/reshaping.html#cross-tabulations\">documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.area, df.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we need to clean the dataset before we can explore it a little more? Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of the junk numbering in `df.areastring`. For single column Pandas Series we use `map`. Here's the <a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.Series.map.html\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.areastring=df.areastring.map(lambda x: x.split('.')[-1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a specific subset of columns of a dataframe, we can use list indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['palmitic','oleic']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this returns a new object of type DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the series of entries of a single column, we could do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df['palmitic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in the syntax. In the first example where we used list indexing we got a new DataFrame. In the second example we got a series corresponding to the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"type of df[['palmitic']]:\\t\", type(df[['palmitic']]) \n",
    "print \"type of df['palmitic']:\\t\\t\", type(df['palmitic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the series of values of a single column more conveniently, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.palmitic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN NOW (10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique areastrings of the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe `dfsub` by taking the list of acids and using pandas' `apply` function to divide all values by 100.\n",
    "\n",
    "If you're not familiar with pandas' `apply` function, a Google search for 'python pandas dataframe apply' points you to the <a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.apply.html\">documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acidlist=['palmitic', 'palmitoleic', 'stearic', 'oleic', 'linoleic', 'linolenic', 'arachidic', 'eicosenoic']\n",
    "\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can replace part of the dataframe by this new frame. Since we need the percentages, let's do this. The `Oleic` percentages should be in the 70s and 80s if you did this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[acidlist]=dfsub\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.palmitic.mean(), df.palmitic.std(), df.palmitic.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.palmitic.std(), np.sqrt(df.palmitic.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.std(df.palmitic), np.mean(df.palmitic), np.var(df.palmitic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.var(df.palmitic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[acidlist].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[acidlist].cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[acidlist].median(), df[acidlist].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quick Intro to Numpy and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a quick and dirty intro. Please read the excellent tutorials <a href=\"http://nbviewer.ipython.org/urls/raw.github.com/jrjohansson/scientific-python-lectures/master/Lecture-2-Numpy.ipynb\">here</a> and <a href=\"http://nbviewer.ipython.org/urls/raw.github.com/jrjohansson/scientific-python-lectures/master/Lecture-4-Matplotlib.ipynb\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Lets start with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = np.array([1,2,3,4])\n",
    "v.shape, type(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in v:\n",
    "    print j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = np.array([[1, 2], [3, 4]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(M), M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M32=np.array([[1,2],[3,4],[5,6]])\n",
    "M32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M23=M32.T\n",
    "M23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.palmitic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['palmitic', 'palmitoleic']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myrandom=np.random.rand(5,3)\n",
    "print myrandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myrandom[0], myrandom[-1], myrandom[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myrandom[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myrandom[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN NOW (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape myrandom into 15 rows of 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Moving on to matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.scatter(df.palmitic, df.linolenic)\n",
    "axis = fig.gca() #get current axis\n",
    "axis.set_title('linolenic vs palmitic')\n",
    "axis.set_xlabel('palmitic')\n",
    "axis.set_ylabel('linolenic')\n",
    "#ax can be got with fig.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df.palmitic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many many more kinds of plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more object oriented approach sees us using the `subplots` function to set both figure and axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes=plt.subplots(figsize=(10,10), nrows=2, ncols=2)\n",
    "axes[0][0].plot(df.palmitic, df.linolenic)\n",
    "axes[0][1].plot(df.palmitic, df.linolenic, '.')\n",
    "axes[1][0].scatter(df.palmitic, df.linolenic)\n",
    "axes[1][1].hist(df.palmitic)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###YOUR TURN NOW (10 minutes)\n",
    "\n",
    "Make scatterplots of the acids in the list `yacids` against the acids in the list `xacids`. As the names suggest, plot the acids in `yacids` along the y axis and the acids in `xacids` along the x axis. Label the axes with the respective acid name. Set it up as a grid with 3 rows and 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xacids=['oleic','linolenic','eicosenoic']\n",
    "yacids=['stearic','arachidic']\n",
    "\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. Pandas Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first concept we deal with here is pandas `groupby`. The idea is to group a dataframe by the values of a particular factor variable. The documentation can be found <a href=\"http://pandas.pydata.org/pandas-docs/dev/groupby.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_groupby = df.groupby('region')\n",
    "print type(region_groupby)\n",
    "region_groupby.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `groupby` gives you a dictionary-like object, with the keys being the values of the factor, and the values being the corresponding subsets of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in region_groupby:\n",
    "    print \"( key, type(value) ) = (\", key, \",\", type(value), \")\"\n",
    "    v=value\n",
    "\n",
    "v.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby` function also acts like an object that can be **mapped**. After the mapping is complete, the rows are put together (**reduced**) into a larger dataframe. For example, using the `describe` function. The documentation of the `describe` function can be found <a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.describe.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfrd=region_groupby.describe()\n",
    "print type(dfrd)\n",
    "dfrd.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one may iterate through the groupby 'dictionary', get the pandas series from each sub-dataframe, and compute the standard deviation using the `std` function (find documentation of `std` <a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.std.html\">here</a>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecs=[]\n",
    "keys=[]\n",
    "for key, value in region_groupby:\n",
    "    k=key\n",
    "    v=value.std()\n",
    "print k, type(v), v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or one might let pandas take care of concatenating the series obtained by running `std` on each dataframe back into a dataframe for us. Notice that the output dataframe is automatically indexed by region for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfbystd=df.groupby('region').std()\n",
    "dfbystd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or one can use `aggregate` to pass an arbitrary function of to the sub-dataframe. The function is applied columnwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfbymean=region_groupby.aggregate(np.mean)\n",
    "dfbymean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_groupby.aggregate(lambda x: x.palmitic.sum()) #probably not what u had in mind :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or one can use `apply` to pass an arbitrary function to the sub-dataframe. This one takes the dataframe as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_groupby.apply(lambda f: f.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_groupby.apply(lambda f: f.palmitic.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns in `dfbymean` and `dfbystd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "renamedict_std={k:k+\"_std\" for k in acidlist}\n",
    "renamedict_mean={k:k+\"_mean\" for k in acidlist}\n",
    "dfbystd.rename(inplace=True, columns=renamedict_std)\n",
    "dfbymean.rename(inplace=True, columns=renamedict_mean) \n",
    "dfbystd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can do general merges. When we do that along an index, it's called a `join` (<a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.join.html\">documentation</a>). Here we make two sub-dataframes and join them on the common region index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfpalmiticmean = dfbymean[['palmitic_mean']] \n",
    "dfpalmiticstd = dfbystd[['palmitic_std']] \n",
    "\n",
    "newdfbyregion=dfpalmiticmean.join(dfpalmiticstd)\n",
    "newdfbyregion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###YOUR TURN NOW (10 minutes)\n",
    "\n",
    "Let's weight the palmitic acids content by a random weight. We'll first extract a subset of columns from `df` and then you will write a function to weigh the palmitic content by this random weight, delivering a weighted palmitic mean in the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights=np.random.uniform(size=df.shape[0])\n",
    "smallerdf=df[['palmitic']]\n",
    "otherdf=df[['region']]\n",
    "otherdf['weight'] = weights\n",
    "otherdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join `smallerdf` and `otherdf` on the index, into smallerdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use these weights to compute a weighted average over the palmitic column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally aggregate the column percentages by summing them up over the regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. One Dimensional Exploratory Data Analysis (EDA) with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rkeys=[1,2,3]\n",
    "rvals=['South','Sardinia','North']\n",
    "rmap={e[0]:e[1] for e in zip(rkeys,rvals)}\n",
    "rmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a dataframe with just the acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf2=df.groupby('region').aggregate(np.mean)\n",
    "mdf2=mdf2[acidlist]\n",
    "mdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a bar plot of the relative mean percentages of the acids. In pandas this is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax=mdf2.plot(kind='barh', stacked=True)\n",
    "ax.set_yticklabels(rvals)\n",
    "ax.set_xlim([0,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.palmitic.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph get's proportions of all the acids in each region. We can ask the opposite question: for each acid, what's the distribution of regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes=plt.subplots(figsize=(10,20), nrows=len(acidlist), ncols=1)\n",
    "i=0\n",
    "for ax in axes.flatten():\n",
    "    acid=acidlist[i]\n",
    "    seriesacid=df[acid]#get the Pandas series\n",
    "    minmax=[seriesacid.min(), seriesacid.max()]\n",
    "    for k,g in df.groupby('region'):\n",
    "        style = {'histtype':'stepfilled', 'alpha':0.5, 'label':rmap[k], 'ax':ax}\n",
    "        g[acid].hist(**style)\n",
    "        ax.set_xlim(minmax)\n",
    "        ax.set_title(acid)\n",
    "        ax.grid(False)\n",
    "    #construct legend\n",
    "    ax.legend()\n",
    "    i=i+1\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask=(df.eicosenoic < 0.05)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first gives a count, the second is a shortcut to get a probability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(mask), np.mean(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports conditional indexing: <a href=\"http://pandas.pydata.org/pandas-docs/dev/indexing.html#boolean-indexing\">documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loweico=df[df.eicosenoic < 0.02]\n",
    "pd.crosstab(loweico.area, loweico.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN NOW (10 minutes)\n",
    "\n",
    "You can see that oleic dominates, and doesn't let us see much about the other acids. Remove it and let's draw bar plots again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acidlistminusoleic=['palmitic', 'palmitoleic', 'stearic', 'linoleic', 'linolenic', 'arachidic', 'eicosenoic']\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that there are no eicosenoic acids in regions 2 and 3, which are Sardinia and the North respectively**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6. Two-dimensional EDA with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write code to scatterplot acid against acid color coded by region. A more polished version is in the appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just do the boxplot without the marginals to split the north out\n",
    "mycolors=['#348ABD', '#A60628', '#7A68A6', '#467821','#D55E00',  '#CC79A7', \n",
    "           '#56B4E9', '#009E73', '#F0E442']\n",
    "cmap=colors.ListedColormap(mycolors)\n",
    "a=np.outer(np.arange(0,1,0.01),np.ones(10))\n",
    "plt.imshow(a.T, cmap=cmap, origin=\"lower\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make2d_eda(df, scatterx, scattery, by=\"region\", labeler={}):\n",
    "    figure=plt.figure(figsize=(8,8))\n",
    "    ax=plt.gca()\n",
    "    cs=list(np.linspace(0,1,len(df.groupby(by))))\n",
    "    xlimsd={}\n",
    "    ylimsd={}\n",
    "    xs={}\n",
    "    ys={}\n",
    "    for k,g in df.groupby(by):\n",
    "        col=cs.pop()\n",
    "        x=g[scatterx]\n",
    "        y=g[scattery]\n",
    "        c=cmap(col)\n",
    "        ax.scatter(x, y, c=c, label=labeler.get(k,k), s=40, alpha=0.4);\n",
    "        xlimsd[k]=ax.get_xlim()\n",
    "        ylimsd[k]=ax.get_ylim()\n",
    "    xlims=[min([xlimsd[k][0] for k in xlimsd]), max([xlimsd[k][1] for k in xlimsd])]\n",
    "    ylims=[min([ylimsd[k][0] for k in ylimsd]), max([ylimsd[k][1] for k in ylimsd])]\n",
    "    ax.set_xlim(xlims)\n",
    "    ax.set_ylim(ylims)\n",
    "    ax.set_xlabel(scatterx)\n",
    "    ax.set_ylabel(scattery)\n",
    "    ax.grid(False)\n",
    "    return ax\n",
    "a=make2d_eda(df, \"linoleic\",\"arachidic\", labeler=rmap)\n",
    "a.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A nonlinear, or even marginally linear classifier could separate the north from Sardinia!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the really ugly trellis rplot interface in Pandas to do some hierarchical digging. We plot oleic against linoleic. **We can split Sardinia. We might be able to split East Liguria out but there could be significant misclassification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas.tools.rplot as rplot\n",
    "dfcopy=df.copy()\n",
    "dfcopy['region']=dfcopy['region'].map(rmap)\n",
    "imap={e[0]:e[1] for e in zip (df.area.unique(), df.areastring.unique())}\n",
    "#dfcopy['area']=dfcopy['area'].map(imap)\n",
    "plot = rplot.RPlot(dfcopy, x='linoleic', y='oleic');\n",
    "plot.add(rplot.TrellisGrid(['region', '.']))\n",
    "plot.add(rplot.GeomPoint(size=40.0, alpha=0.3, colour=rplot.ScaleRandomColour('area')));\n",
    "\n",
    "fig=plot.render()\n",
    "print df.areastring.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN NOW (10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot palmitoleic against palimitic. **What can you separate?** Use the `dfcopy` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7. Probability and  Probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "mu=0.\n",
    "sigma=1.\n",
    "#samples=np.random.normal(mu, sigma, 10000)\n",
    "#plt.hist(samples,bins=25, alpha=0.4, normed=True)\n",
    "nd=stats.norm()\n",
    "plt.hist(nd.rvs(size=10000), bins=50, alpha=0.2,normed=True)\n",
    "x=np.linspace(-4.0,4.0,100)\n",
    "plt.plot(x,nd.pdf(x))\n",
    "plt.plot(x,nd.cdf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = [0,0]\n",
    "cov = [[1,0],[0,5]] # diagonal covariance, points lie on x or y-axis\n",
    "m=300\n",
    "nrvs = np.random.multivariate_normal(mean,cov,(m,m))\n",
    "duets=nrvs.reshape(m*m,2)\n",
    "print duets[:,1]\n",
    "normaldf=pd.DataFrame(dict(x=duets[:,0], y=duets[:,1]))\n",
    "normaldf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H, xedges, yedges = np.histogram2d(normaldf.x, normaldf.y, bins=(50, 50), normed=True)\n",
    "extent = [xedges[0], xedges[-1], yedges[-1], yedges[0]]\n",
    "plt.imshow(H, extent=extent, interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8. Miscellaneous Pandas Plotting tools: scatters, boxplots, and parallel co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(df[['linoleic','arachidic','eicosenoic']], alpha=0.3, figsize=(10, 10), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,20))\n",
    "for key, group in df.groupby('region'):\n",
    "    plt.subplot(int('31'+str(key)))\n",
    "    group[acidlistminusoleic].boxplot(grid=False)\n",
    "    ax=plt.gca()\n",
    "    ax.set_title(rvals[key-1])\n",
    "    ax.grid(axis=\"y\", color=\"gray\", linestyle=':', lw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import parallel_coordinates\n",
    "dfna=df[['region', 'palmitic', 'palmitoleic', 'stearic', 'oleic', 'linolenic', 'linoleic', 'arachidic', 'eicosenoic']]\n",
    "dfna_norm = (dfna - dfna.mean()) / (dfna.max() - dfna.min())\n",
    "dfna_norm['region']=df['region'].map(lambda x: rmap[x])\n",
    "parallel_coordinates(dfna_norm, 'region', alpha=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
